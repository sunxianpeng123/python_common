sklearn svm实用窍门
    1、避免数据复制：对SVC，SVR，NuSVC和 NuSVR，如果通过一定的方法将数据不是C有序连续的，而双精度，它会调用底层的C实现之前复制。您可以通过检查其flags属性来检查给定的numpy数组是否为C 连续的。
    2、对于LinearSVC（和LogisticRegression）作为numpy数组传递的任何输入将被复制并转换为liblinear内部稀疏数据表示（非零组件的双精度浮点数和int32索引）。如果你想要适合一个大规模的线性分类器，
    而不需要复制一个密集的数字C连续的双精度数组作为输入，我们建议使用SGDClassifier该类。目标函数可以配置为与LinearSVC 模型几乎相同。
    3、内核缓存大小：对SVC，SVR，nuSVC和 NuSVR，内核缓存的大小有较大的问题，在运行时间有很大的影响。如果您有足够的RAM可用，建议设置cache_size为比默认值200（MB）更高的值，例如500（MB）或1000（MB）。
    4、设置为C：C是1在默认情况下，这是一个合理的默认选择。如果你有很多嘈杂的观察结果，你应该减少它。它对应于更多的估计。
    5、支持向量机算法不是尺度不变量，因此强烈建议您扩展数据。例如，将输入向量X上的每个属性缩放到[0,1]或[-1，+ 1]，或将其标准化为平均值0和方差1.注意，必须将相同的缩放应用于测试向量获得有意义的结果。
    有关缩放和归一化的更多详细信息，请参见 预处理数据。
    6、参数nu在NuSVC/ OneClassSVM/ NuSVR 近似训练误差和支持向量的分数。
    7、在SVC，如果用于分类的数据不平衡（例如，许多正数和少量负数），请设置class_weight='balanced'和/或尝试不同的惩罚参数C。
    8、底层LinearSVC实现使用随机数生成器来在拟合模型时选择特征。因此，相同输入数据的结果略有不同，因此并不罕见。如果发生这种情况，请尝试使用较小的tol参数。
    9、使用提供的L1惩罚产生稀疏解，即只有特征权重的子集不同于零，并有助于决策函数。增加产量是一个更复杂的模型（选择更多的特征）。可以使用产生“零”模型（所有权重等于零）的值。
    LinearSVC(loss='l2', penalty='l1', dual=False)CCl1_min_c